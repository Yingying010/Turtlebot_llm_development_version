from transformers import AutoTokenizer, AutoModelForCausalLM
import torch, re, ast, json, time
from textwrap import dedent
from stream_tts import tts_manager
from loguru import logger
from config import config
import control_turtlebot
from llama_cpp import Llama

print("â³ Loading tokenizer and model...")
start = time.time()
model_path = "models/Qwen3_single_move_turn_q4_k_m.gguf"  # ä½ é‡åŒ–åçš„æ¨¡å‹è·¯å¾„
llm = Llama(
    model_path=model_path,
    n_ctx=2048,
    n_threads=4,  # æ ¹æ®ä½  CPU è°ƒæ•´
    verbose=True,
)
print(f"âœ… Model loaded in {time.time() - start:.2f} seconds")

# ===== Prompt æ„å»ºæ¨¡æ¿ =====
system_prompt = dedent('''
You are a robot command parser. Given a natural language instruction, output ONLY a valid JSON object that follows the format below.

JSON Format:
{
  "<robot_name>": [
    {
      "action": "move" | "turn",
      "direction": "left" | "right" | "forward" | "backward",
      "value": <number>,
      "unit": "seconds" | "meters" | "degrees"
    }
  ]
}

Rules:
 - Do NOT output any explanation or reasoning.
 - You MUST include the robot name as the top-level key.
 - Only output a valid object followed by the format.
''').strip()

def build_prompt(instruction: str) -> str:
    return """<|system|>\n{system_prompt}\n<|user|>\n{instruction}\n<|assistant|>\n"""

# ===== ç”Ÿæˆ JSON =====
def generate_response(user_input, max_new_tokens=256):
    print("ğŸŒ€ Generating response...")
    start = time.time()
    output = llm(prompt, max_tokens=256, stop=["<|user|>", "<|system|>"])
    end = time.time()

    response = output["choices"][0]["text"].strip()
    print("=== Raw Response ===\n", response)

    result = extract_json(response)
    print("\n=================== JSON Result ===================")
    print(result)
    print(f"âœ… Generation completed in {end - start:.2f} seconds")
    return result

# === JSON æå– ===
def extract_json(text: str):
    start = text.find('{')
    while start != -1:
        stack = 0
        for i in range(start, len(text)):
            if text[i] == '{':
                stack += 1
            elif text[i] == '}':
                stack -= 1
            if stack == 0:
                try:
                    return json.loads(text[start:i+1])
                except:
                    break
        start = text.find('{', start + 1)
    return None


# ===== ä¸»æ‰§è¡Œå‡½æ•° =====
def run(user_input):
    logger.info(f"ğŸ’¡ Mode: {'Chat' if config.get('chat_or_instruct') else 'Control'}")
    logger.info(f"ğŸ§  LLM Input: {user_input}")
    response = generate_response(user_input)
    # print("\nğŸ§  Raw LLM Output:\n", response)
    commands = extract_json(response)
    if commands:
        print("\nâœ… Parsed JSON:\n", commands)
    else:
        print("\nâŒ Failed to extract valid JSON.")
    return commands

# ===== æµ‹è¯•å…¥å£ =====
if __name__ == "__main__":
    user_input = "let turtlebot1 forward 2 meters and turn left 45 degrees"
    command = run(user_input)
    if command:
        control_turtlebot.run(command)
        tts_manager.say("Command executed.")
        logger.info("âœ… Command(s) executed successfully.")
