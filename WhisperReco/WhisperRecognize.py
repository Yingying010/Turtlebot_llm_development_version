import sys, os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import queue, threading, time, re, subprocess
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write
from scipy.signal import butter, lfilter
from loguru import logger
from config import config
from stream_tts import tts_manager
from typing import Final
import wave

conversation_active: Final[threading.Event] = threading.Event()

# === ä¼˜åŒ–åçš„å‚æ•° ===
SAMPLERATE = 16000  # é™ä½é‡‡æ ·ç‡ä»48kHzåˆ°16kHz
BLOCKSIZE = 1024
SILENCE_THRESHOLD = 20.0  # æé«˜é™éŸ³é˜ˆå€¼
SILENCE_DURATION = 0.8    # ç¼©çŸ­é™éŸ³æŒç»­æ—¶é—´
MAX_DURATION = 8          # ç¼©çŸ­æœ€å¤§å½•éŸ³æ—¶é•¿
FIXED_WAV_PATH = "/dev/shm/voice_input.wav"  # ä½¿ç”¨å†…å­˜æ–‡ä»¶ç³»ç»Ÿ
PRE_SPEECH_BUFFER_SIZE = 24  # é¢„å½•éŸ³ç¼“å†²åŒºå¤§å°

# === éŸ³é¢‘æ»¤æ³¢å‡½æ•° ===
def butter_highpass(cutoff, fs, order=5):
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='high', analog=False)
    return b, a

def highpass_filter(data, cutoff=100, fs=SAMPLERATE, order=5):
    b, a = butter_highpass(cutoff, fs, order=order)
    y = lfilter(b, a, data)
    return y

# === æ¸…ç†æ–‡æœ¬ ===
def _clean(text: str) -> str:
    return re.sub(r'[^\w\s]', '', text).lower().strip()

# === æ ‡å‡†å†™å…¥ wav æ–‡ä»¶ ===
def save_wav_standard(wav_path, audio_int16, samplerate=16000):
    with wave.open(wav_path, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)  # 16-bit PCM
        wf.setframerate(samplerate)
        wf.writeframes(audio_int16.tobytes())

# === å½•éŸ³ç›´åˆ°é™éŸ³ç»“æŸ ===
def record_until_silence(threshold=SILENCE_THRESHOLD,
                         silence_duration=SILENCE_DURATION,
                         max_duration=MAX_DURATION) -> str:
    q_local = queue.Queue()
    silence_blocks = int(silence_duration * SAMPLERATE / BLOCKSIZE)
    max_blocks = int(max_duration * SAMPLERATE / BLOCKSIZE)

    pre_speech_buffer = []  # ä¿å­˜æœ€è¿‘çš„å‡ ä¸ªå—
    audio_blocks = []
    silence_counter = 0
    is_recording = False

    def cb(indata, frames, time_info, status):
        if status:
            logger.warning(f"âš ï¸ Audio status: {status}")
        q_local.put(indata.copy())

    logger.info("ğŸ™ï¸ Waiting for speech to start...")

    with sd.InputStream(samplerate=SAMPLERATE, channels=1,
                       blocksize=BLOCKSIZE, callback=cb, dtype='float32'):
        while True:
            try:
                block = q_local.get(timeout=1)
            except queue.Empty:
                continue

            volume = np.abs(block).mean() * 1000
            logger.debug(f"ğŸ“Š Vol: {volume:.1f}")

            # ç»´æŠ¤é¢„å½•éŸ³ç¼“å†²åŒº
            pre_speech_buffer.append(block)
            if len(pre_speech_buffer) > PRE_SPEECH_BUFFER_SIZE:
                pre_speech_buffer.pop(0)

            if not is_recording:
                if volume > threshold:
                    logger.info("ğŸ”´ Voice detected. Start recording...")
                    is_recording = True
                    audio_blocks.extend(pre_speech_buffer)  # åŠ ä¸Šå‰é¢çš„ç¼“å­˜
                    audio_blocks.append(block)
                continue

            audio_blocks.append(block)

            if volume < threshold:
                silence_counter += 1
                if silence_counter >= silence_blocks:
                    logger.info("ğŸ”‡ Silence detected. Stopping recording.")
                    break
            else:
                silence_counter = 0

            if len(audio_blocks) >= max_blocks:
                logger.info("â° Max recording length reached. Forcing stop.")
                break

    # === éŸ³é¢‘å¤„ç†å¹¶ä¿å­˜ ===
    pcm_f32 = np.concatenate(audio_blocks).flatten()
    pcm_f32 = highpass_filter(pcm_f32)  # æ·»åŠ é«˜é€šæ»¤æ³¢
    pcm_i16 = (pcm_f32 * 32767).clip(-32768, 32767).astype(np.int16)

    save_wav_standard(FIXED_WAV_PATH, pcm_i16, SAMPLERATE)
    logger.success(f"ğŸ’¾ Saved recording to {FIXED_WAV_PATH}")
    return FIXED_WAV_PATH

# === è°ƒç”¨ whisper-cli è½¬å½• ===
def transcribe_audio(wav_path: str, delay: float = 0.0) -> str:
    model_path = os.path.expanduser("~/whisper.cpp/models/ggml-tiny.en.bin")  # ä½¿ç”¨æ›´å°æ¨¡å‹
    cli_path = os.path.expanduser("~/whisper.cpp/build/bin/whisper-cli")
    cmd = [cli_path, "-m", model_path, "-f", wav_path, "-t", "2", "--step", "500", "--length", "500"]  # ä¼˜åŒ–å‚æ•°

    result = subprocess.run(cmd, capture_output=True, text=True)
    output = result.stdout.strip()

    # æå–è¯†åˆ«æ–‡æœ¬è¡Œ
    lines = output.splitlines()
    text_lines = [
        line.split("]", 1)[-1].strip(" -\t") for line in lines
        if "-->" in line and "]" in line
    ]
    raw_text = " ".join(text_lines).strip()
    clean_text = _clean(raw_text)

    logger.success(f"ğŸ“ Transcribed Text: {clean_text or '<EMPTY>'}")
    if delay:
        time.sleep(delay)
    return clean_text

# === è¯†åˆ«å‡½æ•° ===
def recognize(delay: float = 0.0) -> str:
    wav_path = record_until_silence()
    return transcribe_audio(wav_path, delay)

# === åå°çƒ­è¯è¯†åˆ«çº¿ç¨‹ ===
def Whisper_run(callback_func):
    def loop():
        print("ğŸŸ¢ Whisper hotword loop started")
        while True:
            if conversation_active.is_set():
                time.sleep(0.2)
                continue

            raw_text = recognize(delay=3)
            clean_text = _clean(raw_text)
            if not clean_text:
                continue

            if "open robot system" in clean_text:
                config.set(chat_or_instruct=False)
                logger.info("ğŸ® Switched to CONTROL mode.")
                tts_manager.say("Okay, I'm now in control mode.")
                conversation_active.set()
                callback_func()

            elif "hi assistant" in clean_text:
                config.set(chat_or_instruct=True)
                logger.info("ğŸ’¬ Switched to CHAT mode.")
                tts_manager.say("Sure, I'm now in chat mode.")
                conversation_active.set()
                callback_func()

            elif clean_text in {"ok bye", "okay bye", "ok byebye", "okay byebye"}:
                tts_manager.say("Goodbye!")
                time.sleep(1)
                os._exit(0)

    threading.Thread(target=loop, daemon=True).start()

# === æµ‹è¯•å…¥å£ ===
if __name__ == "__main__":
    logger.info("ğŸ¤ Start single recognition test...")
    result = recognize()
    print("ğŸ—£ï¸ You said:", result or "<nothing>")