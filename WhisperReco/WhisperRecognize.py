import os
import sys
import queue
import threading
import time
import re
import numpy as np
import sounddevice as sd
import soundfile as sf
from loguru import logger
from typing import Final, Optional
import whisper

# === åŠ è½½ Whisper base.en æ¨¡å‹ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜ï¼‰ ===
model = whisper.load_model("base.en")
conversation_active: Final[threading.Event] = threading.Event()

# === å‚æ•°ä¼˜åŒ– ===
# SAMPLERATE = 16000
BLOCKSIZE = 2048
SILENCE_THRESHOLD = 10.0
SILENCE_DURATION = 1.5
MIN_ACTIVATION_DURATION = 0.3
TEMP_WAV_PATH = "/tmp/current_audio.wav"

class WhisperRecognizer:
    def __init__(self):
        # ç”¨äºå­˜æ”¾éŸ³é¢‘ç‰‡æ®µ
        self.audio_buffer: list[np.ndarray] = []
        # å…ˆè®¾ç½®ä¸€ä¸ªå ä½ï¼Œå®é™…é‡‡æ ·ç‡åœ¨ start() é‡Œè¦†ç›–
        self.samplerate: float = None  
        # ç”¨äºå¯¹å¤–è¿”å›è½¬å½•ç»“æœ
        self.result_queue: queue.Queue[str] = queue.Queue()
        self.stream: Optional[sd.InputStream] = None
        self.speech_start_time = 0.0
        self.last_audio_time = 0.0
        self.is_speaking = False

        # çƒ­è¯
        self.key_phrases = {
            "activate control": ["open robot system", "activate robot", "robot mode"],
            "activate chat":    ["hi assistant", "hey assistant", "start chat"],
            "shutdown":         ["ok bye", "okay bye", "goodbye", "exit"],
        }

        logger.success("ğŸŸ¢ Whisper è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")

    def _audio_callback(self, indata, frames, time_info, status):
        if status:
            logger.warning(f"éŸ³é¢‘çŠ¶æ€: {status}")

        self.audio_buffer.append(indata.copy())
        volume = np.abs(indata).mean() * 1000
        now = time.time()

        if volume > SILENCE_THRESHOLD:
            self.last_audio_time = now
            if not self.is_speaking:
                self.speech_start_time = now
                self.is_speaking = True
                logger.info("ğŸ”´ æ£€æµ‹åˆ°è¯­éŸ³")
        elif self.is_speaking and (now - self.last_audio_time > SILENCE_DURATION):
            self.is_speaking = False
            logger.info("ğŸ”‡ é™éŸ³æ£€æµ‹ï¼Œå¼€å§‹å¤„ç†â€¦")
            # å¼‚æ­¥å¤„ç†ï¼Œé˜²æ­¢é˜»å¡å›è°ƒ
            threading.Thread(target=self._process_audio, daemon=True).start()

    def start(self):
        """å¯åŠ¨éŸ³é¢‘æµ"""
       # åŠ¨æ€æ¢æµ‹é»˜è®¤è¾“å…¥è®¾å¤‡çš„é‡‡æ ·ç‡
        device_info = sd.query_devices(kind='input')
        self.samplerate = int(device_info['default_samplerate'])
        logger.info(f"ğŸ›  ä¾¦æµ‹åˆ°è¾“å…¥è®¾å¤‡é»˜è®¤é‡‡æ ·ç‡: {self.samplerate} Hz")

        self.stream = sd.InputStream(
            samplerate=self.samplerate,
            channels=1,
            blocksize=BLOCKSIZE,
            dtype='float32',
            callback=self._audio_callback
        )
        self.stream.start()
        logger.info("ğŸ™ï¸ éŸ³é¢‘æµå·²å¯åŠ¨")

    def _save_audio(self) -> bool:
        if not self.audio_buffer:
            return False
        audio = np.concatenate(self.audio_buffer, axis=0)
        # ä¿å­˜æ—¶ä½¿ç”¨å®é™…çš„é‡‡æ ·ç‡ï¼Œä¿è¯ä¸€è‡´
        sf.write(TEMP_WAV_PATH, audio, self.samplerate, format='WAV', subtype='PCM_16')
        self.audio_buffer = []
        return True

    def _process_audio(self):
        if not self._save_audio():
            return

        if time.time() - self.speech_start_time < MIN_ACTIVATION_DURATION:
            logger.debug("ğŸŒ“ è¯­éŸ³å¤ªçŸ­ï¼Œè·³è¿‡è½¬å½•")
            return

        try:
            result = model.transcribe(TEMP_WAV_PATH, language="en", fp16=False)
            transcript = result.get("text", "").strip()
        except Exception as e:
            logger.error(f"âŒ è½¬å½•å¤±è´¥: {e}")
            return

        if transcript:
            logger.info(f"ğŸ“ è½¬å½•ç»“æœ: {transcript}")
            # æ”¾å…¥é˜Ÿåˆ—ï¼Œä¾›å¤–éƒ¨è·å–
            self.result_queue.put(transcript)
            self._check_for_keywords(transcript)

    def _check_for_keywords(self, text: str):
        t = text.lower()
        if conversation_active.is_set():
            if any(p in t for p in self.key_phrases["shutdown"]):
                logger.info("ğŸ›‘ æ£€æµ‹åˆ°å…³é—­å‘½ä»¤")
                self._shutdown()
            return

        if any(p in t for p in self.key_phrases["activate control"]):
            logger.info("ğŸ® åˆ‡æ¢åˆ°æ§åˆ¶æ¨¡å¼")
            conversation_active.set()
        elif any(p in t for p in self.key_phrases["activate chat"]):
            logger.info("ğŸ’¬ åˆ‡æ¢åˆ°èŠå¤©æ¨¡å¼")
            conversation_active.set()
        elif any(p in t for p in self.key_phrases["shutdown"]):
            logger.info("ğŸ›‘ æ£€æµ‹åˆ°å…³é—­å‘½ä»¤")
            self._shutdown()

    def get_result(self, timeout: Optional[float] = None) -> str:
        """
        ä»å†…éƒ¨é˜Ÿåˆ—è·å–ä¸‹ä¸€æ¡è½¬å½•ç»“æœã€‚
        :param timeout: é˜»å¡ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone åˆ™æ— é™ç­‰å¾…
        :raises queue.Empty: å¦‚æœè¶…æ—¶æœªå¾—åˆ°ç»“æœ
        """
        return self.result_queue.get(timeout=timeout)

    def _shutdown(self):
        if self.stream:
            self.stream.stop()
            self.stream.close()
        logger.success("âœ… ç³»ç»Ÿå·²å®‰å…¨å…³é—­")
        sys.exit(0)


# === æ¨¡å—æµ‹è¯•æˆ–ç¤ºä¾‹ç”¨æ³• ===
if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨ Whisper è¯­éŸ³è¯†åˆ«æ¨¡å—")
    recognizer = WhisperRecognizer()
    recognizer.start()
    logger.info("ğŸ§ ç³»ç»Ÿå°±ç»ªï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥â€¦")

    try:
        while True:
            # é˜»å¡ç­‰å¾…ä¸‹ä¸€æ¡è½¬å½•æ–‡æœ¬ï¼Œæœ€å¤šç­‰ 5 ç§’
            try:
                text = recognizer.get_result(timeout=5.0)
                print(f"ä¸»ç¨‹åºæ‹¿åˆ°è½¬å½•: {text}")
                # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å¤„ç† textï¼Œæ¯”å¦‚å‘ç»™èŠå¤©æœºå™¨äººç­‰
            except queue.Empty:
                # 5 ç§’æ— è¾“å…¥ï¼Œç»§ç»­ç­‰å¾…
                continue

    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œç³»ç»Ÿå…³é—­")
        recognizer._shutdown()
