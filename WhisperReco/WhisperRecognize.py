import sys
import os
import queue
import threading
import time
import re
import subprocess
import tempfile
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write
from loguru import logger
from config import config
from stream_tts import tts_manager
from typing import Final
import wave

conversation_active: Final[threading.Event] = threading.Event()

# === å‚æ•°è®¾ç½® ===
SAMPLERATE = 48000  # ä¿æŒ48000Hzé‡‡æ ·ç‡
BLOCKSIZE = 1024    # é€‚åˆ48000Hzçš„å—å¤§å°
SILENCE_THRESHOLD = 15.0
SILENCE_DURATION = 1.0
MAX_DURATION = 10
FIXED_WAV_PATH = "/tmp/voice_input.wav"

# === æ¸…ç†æ–‡æœ¬ ===
def _clean(text: str) -> str:
    return re.sub(r'[^\w\s]', '', text).lower().strip()

# === æ ‡å‡†å†™å…¥ wav æ–‡ä»¶ ===
def save_wav_standard(wav_path, audio_int16, samplerate=48000):
    with wave.open(wav_path, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)  # 16-bit PCM
        wf.setframerate(samplerate)
        wf.writeframes(audio_int16.tobytes())

# === å½•éŸ³ç›´åˆ°é™éŸ³ç»“æŸ (ä¼˜åŒ–ç‰ˆ) ===
def record_until_silence(threshold=SILENCE_THRESHOLD,
                         silence_duration=SILENCE_DURATION,
                         max_duration=MAX_DURATION) -> str:
    q_local = queue.Queue()
    silence_blocks = int(silence_duration * SAMPLERATE / BLOCKSIZE)
    max_blocks = int(max_duration * SAMPLERATE / BLOCKSIZE)

    pre_speech_buffer = []
    pre_speech_maxlen = 24
    silence_counter = 0
    is_recording = False

    # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è€Œä¸æ˜¯å†…å­˜å­˜å‚¨
    temp_wav = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
    temp_path = temp_wav.name
    temp_wav.close()

    def cb(indata, frames, time_info, status):
        nonlocal is_recording, silence_counter
        if status:
            logger.warning(f"âš ï¸ Audio status: {status}")
        
        block = indata.copy()
        volume = np.abs(block).mean() * 1000
        logger.debug(f"ğŸ“Š Vol: {volume:.1f}")

        # å®æ—¶éŸ³é¢‘å¤„ç†
        block = block * 1.2  # å¢ç›Šæ§åˆ¶
        block = np.clip(block, -1.0, 1.0)

        q_local.put((block, volume))

    logger.info("ğŸ™ï¸ Waiting for speech to start...")

    with sd.InputStream(samplerate=SAMPLERATE, channels=1,
                      blocksize=BLOCKSIZE, callback=cb):
        with wave.open(temp_path, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLERATE)

            while True:
                try:
                    block, volume = q_local.get(timeout=1)
                except queue.Empty:
                    continue

                # ç»´æŠ¤å‰å‡ ä¸ªblockçš„ç¼“å­˜
                pre_speech_buffer.append(block)
                if len(pre_speech_buffer) > pre_speech_maxlen:
                    pre_speech_buffer.pop(0)

                if not is_recording:
                    if volume > threshold:
                        logger.info("ğŸ”´ Voice detected. Start recording...")
                        is_recording = True
                        # å†™å…¥ç¼“å­˜å—
                        for buf_block in pre_speech_buffer:
                            pcm_i16 = (buf_block * 32767).clip(-32768, 32767).astype(np.int16)
                            wf.writeframes(pcm_i16.tobytes())
                        # å†™å…¥å½“å‰å—
                        pcm_i16 = (block * 32767).clip(-32768, 32767).astype(np.int16)
                        wf.writeframes(pcm_i16.tobytes())
                    continue

                # å†™å…¥å½“å‰å—
                pcm_i16 = (block * 32767).clip(-32768, 32767).astype(np.int16)
                wf.writeframes(pcm_i16.tobytes())

                if volume < threshold:
                    silence_counter += 1
                    if silence_counter >= silence_blocks:
                        logger.info("ğŸ”‡ Silence detected. Stopping recording.")
                        break
                else:
                    silence_counter = 0

                if wf.getnframes() >= max_duration * SAMPLERATE:
                    logger.info("â° Max recording length reached. Forcing stop.")
                    break

    logger.success(f"ğŸ’¾ Saved recording to {temp_path}")
    return temp_path

# === è°ƒç”¨ whisper-cli è½¬å½• (ä¼˜åŒ–ç‰ˆ) ===
def transcribe_audio(wav_path: str, delay: float = 0.0) -> str:
    model_path = os.path.expanduser("~/whisper.cpp/models/ggml-base.en.bin")
    cli_path = os.path.expanduser("~/whisper.cpp/build/bin/whisper-cli")
    cmd = [
        cli_path,
        "-m", model_path,
        "-f", wav_path,
        "-t", "4",  # ä½¿ç”¨4ä¸ªçº¿ç¨‹
        "--language", "en",  # æ˜ç¡®æŒ‡å®šè¯­è¨€
        "--translate",  # å¦‚æœåªéœ€è¦è‹±æ–‡
        "--speed-up"  # å¯ç”¨åŠ é€Ÿæ¨¡å¼(å¦‚æœwhisperç‰ˆæœ¬æ”¯æŒ)
    ]

    try:
        # æ·»åŠ è¶…æ—¶é˜²æ­¢å¡æ­»
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        output = result.stdout.strip()
    except subprocess.TimeoutExpired:
        logger.error("Whisper transcription timed out")
        return ""

    # æå–è¯†åˆ«æ–‡æœ¬è¡Œ
    lines = output.splitlines()
    text_lines = [
        line.split("]", 1)[-1].strip(" -\t") for line in lines
        if "-->" in line and "]" in line
    ]
    raw_text = " ".join(text_lines).strip()

    clean_text = _clean(raw_text)
    logger.success(f"ğŸ“ Transcribed Text: {clean_text or '<EMPTY>'}")
    
    if delay:
        time.sleep(delay)
    
    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    try:
        os.unlink(wav_path)
    except:
        pass
    
    return clean_text

# === å¹¶è¡Œè¯†åˆ«å‡½æ•° ===
def recognize(delay: float = 0.0) -> str:
    transcription_queue = queue.Queue()
    
    def record_and_transcribe():
        wav_path = record_until_silence()
        result = transcribe_audio(wav_path, delay)
        transcription_queue.put(result)
    
    # å¯åŠ¨å½•éŸ³å’Œè½¬å½•çº¿ç¨‹
    threading.Thread(target=record_and_transcribe, daemon=True).start()
    
    # ç­‰å¾…ç»“æœï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ è¶…æ—¶
    try:
        return transcription_queue.get(timeout=MAX_DURATION + 15)  # æœ€å¤§å½•éŸ³æ—¶é—´+15ç§’ç¼“å†²
    except queue.Empty:
        logger.warning("Recognition timed out")
        return ""

# === åå°çƒ­è¯è¯†åˆ«çº¿ç¨‹ (ä¼˜åŒ–ç‰ˆ) ===
def Whisper_run(callback_func):
    def loop():
        print("ğŸŸ¢ Whisper hotword loop started")
        while True:
            if conversation_active.is_set():
                time.sleep(0.2)
                continue

            clean_text = recognize(delay=3)
            if not clean_text:
                continue

            if "open robot system" in clean_text:
                config.set(chat_or_instruct=False)
                logger.info("ğŸ® Switched to CONTROL mode.")
                tts_manager.say("Okay, I'm now in control mode.")
                conversation_active.set()
                callback_func()

            elif "hi assistant" in clean_text:
                config.set(chat_or_instruct=True)
                logger.info("ğŸ’¬ Switched to CHAT mode.")
                tts_manager.say("Sure, I'm now in chat mode.")
                conversation_active.set()
                callback_func()

            elif clean_text in {"ok bye", "okay bye", "ok byebye", "okay byebye"}:
                tts_manager.say("Goodbye!")
                time.sleep(1)
                os._exit(0)

    threading.Thread(target=loop, daemon=True).start()

# === æµ‹è¯•å…¥å£ ===
if __name__ == "__main__":
    logger.info("ğŸ¤ Start single recognition test...")
    result = recognize()
    print("ğŸ—£ï¸ You said:", result or "<nothing>")